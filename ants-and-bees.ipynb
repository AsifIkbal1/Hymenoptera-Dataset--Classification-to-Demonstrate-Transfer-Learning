{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Ants and Bees - Classification to Demonstrate Transfer Learning\n\n- This notebook is supposed to be an amateur's first foray into Transfer Learning.\n- It operates on a dataset that is relatively small - with 120 images for ants and bees. There are 75 validation images for each class as well.\n- Usually, this is a very small dataset to generalize upon, if trained from scratch. Since we are using transfer learning, we should be able to generalize reasonably well.","metadata":{"papermill":{"duration":0.006497,"end_time":"2022-10-19T18:08:17.004432","exception":false,"start_time":"2022-10-19T18:08:16.997935","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"### Relevant Imports","metadata":{"papermill":{"duration":0.005022,"end_time":"2022-10-19T18:08:17.015426","exception":false,"start_time":"2022-10-19T18:08:17.010404","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import torch\nfrom torch import nn, optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import DataLoader\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, transforms as T, models\nimport matplotlib.pyplot as plt\nimport time\nimport os\n\nplt.ion()","metadata":{"execution":{"iopub.execute_input":"2022-10-19T18:08:17.031019Z","iopub.status.busy":"2022-10-19T18:08:17.029724Z","iopub.status.idle":"2022-10-19T18:08:19.16579Z","shell.execute_reply":"2022-10-19T18:08:19.164745Z"},"papermill":{"duration":2.147476,"end_time":"2022-10-19T18:08:19.168114","exception":false,"start_time":"2022-10-19T18:08:17.020638","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load Data","metadata":{"papermill":{"duration":0.005113,"end_time":"2022-10-19T18:08:19.1789","exception":false,"start_time":"2022-10-19T18:08:19.173787","status":"completed"},"tags":[]}},{"cell_type":"code","source":"data_transforms = {\n    'train': T.Compose([\n        T.RandomResizedCrop(224),\n        T.RandomHorizontalFlip(),\n        T.ToTensor(),\n        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'val': T.Compose([\n        T.Resize(256),\n        T.CenterCrop(224),\n        T.ToTensor(),\n        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ])\n}","metadata":{"execution":{"iopub.execute_input":"2022-10-19T18:08:19.191679Z","iopub.status.busy":"2022-10-19T18:08:19.190888Z","iopub.status.idle":"2022-10-19T18:08:19.198527Z","shell.execute_reply":"2022-10-19T18:08:19.19754Z"},"papermill":{"duration":0.016578,"end_time":"2022-10-19T18:08:19.200888","exception":false,"start_time":"2022-10-19T18:08:19.18431","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 4","metadata":{"execution":{"iopub.execute_input":"2022-10-19T18:08:19.213894Z","iopub.status.busy":"2022-10-19T18:08:19.213524Z","iopub.status.idle":"2022-10-19T18:08:19.218078Z","shell.execute_reply":"2022-10-19T18:08:19.217018Z"},"papermill":{"duration":0.013617,"end_time":"2022-10-19T18:08:19.220217","exception":false,"start_time":"2022-10-19T18:08:19.2066","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from os import path\n\ndata_dir = \"../input/hymenoptera/hymenoptera\"\n# data_dir = path.join(data_dest)\n\nimage_datasets = {x: datasets.ImageFolder(\n    os.path.join(data_dir, x), transform=data_transforms[x]) for x in ['train', 'val']}\ndataloaders = {x: DataLoader(image_datasets[x], batch_size=batch_size, shuffle=(\n    True if x == 'train' else False), num_workers=2) for x in ['train', 'val']}\n\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\ncategory_names = image_datasets['train'].classes\n","metadata":{"execution":{"iopub.execute_input":"2022-10-19T18:08:19.232994Z","iopub.status.busy":"2022-10-19T18:08:19.232374Z","iopub.status.idle":"2022-10-19T18:08:19.287828Z","shell.execute_reply":"2022-10-19T18:08:19.286906Z"},"papermill":{"duration":0.064596,"end_time":"2022-10-19T18:08:19.290363","exception":false,"start_time":"2022-10-19T18:08:19.225767","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.execute_input":"2022-10-19T18:08:19.302751Z","iopub.status.busy":"2022-10-19T18:08:19.302474Z","iopub.status.idle":"2022-10-19T18:08:19.377392Z","shell.execute_reply":"2022-10-19T18:08:19.376293Z"},"papermill":{"duration":0.08318,"end_time":"2022-10-19T18:08:19.379584","exception":false,"start_time":"2022-10-19T18:08:19.296404","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualising a Few Images\n\n- We'll plot a few images to see the effects of the data transforms.","metadata":{"papermill":{"duration":0.006019,"end_time":"2022-10-19T18:08:19.392122","exception":false,"start_time":"2022-10-19T18:08:19.386103","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from torch import Tensor\n\n\ndef imshow(inp: Tensor, title=None):\n  \"\"\"Plot image if `inp` is a tensor\"\"\"\n\n  inp = inp.cpu().numpy().transpose((1, 2, 0))\n  mean = np.array([0.485, 0.456, 0.406])\n  std = np.array([0.229, 0.224, 0.225])\n\n  inp = std * inp + mean\n  np.clip(inp, 0, 1)\n\n  if title is not None:\n    plt.title(title)\n\n  return plt.imshow(inp)\n","metadata":{"execution":{"iopub.execute_input":"2022-10-19T18:08:19.406508Z","iopub.status.busy":"2022-10-19T18:08:19.40563Z","iopub.status.idle":"2022-10-19T18:08:19.414182Z","shell.execute_reply":"2022-10-19T18:08:19.413109Z"},"papermill":{"duration":0.018195,"end_time":"2022-10-19T18:08:19.416607","exception":false,"start_time":"2022-10-19T18:08:19.398412","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get a batch of training data\ninputs, classes = next(iter(dataloaders['train']))\n\n# make a grid from batch\nout = torchvision.utils.make_grid(inputs)\n\nimshow(out, [category_names[x] for x in classes])\n","metadata":{"execution":{"iopub.execute_input":"2022-10-19T18:08:19.431825Z","iopub.status.busy":"2022-10-19T18:08:19.431459Z","iopub.status.idle":"2022-10-19T18:08:19.972175Z","shell.execute_reply":"2022-10-19T18:08:19.971173Z"},"papermill":{"duration":0.551878,"end_time":"2022-10-19T18:08:19.975137","exception":false,"start_time":"2022-10-19T18:08:19.423259","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training the Model\n\nIt will help us to:\n  - schedule the learning rate\n  - saving the best model","metadata":{"papermill":{"duration":0.006179,"end_time":"2022-10-19T18:08:19.988027","exception":false,"start_time":"2022-10-19T18:08:19.981848","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from copy import deepcopy\nfrom torch.nn import Module\n\n\ndef train_model(model: Module, criterion, optimizer: optim.Optimizer, scheduler, num_epochs=25):\n  since = time.time()\n\n  best_model_wts = deepcopy(model.state_dict())\n  best_acc = 0.0\n\n  for epoch in range(num_epochs):\n    print(f\"Epoch: {epoch} / {num_epochs}\")\n\n    for phase in ['train', 'val']:\n      if phase == 'train':\n        model.train()\n\n      else:\n        model.eval()\n\n      running_loss, running_corrects = 0.0, 0\n\n      for inputs, labels in dataloaders[phase]:\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        # zero all the layers' parameters gradients\n        optimizer.zero_grad()\n\n        # feed forward\n        with torch.set_grad_enabled(phase == 'train'):\n          outputs = model(inputs)\n          _, preds = torch.max(outputs, dim=1)\n          loss = criterion(outputs, labels)\n\n          # backpropagate loss only if training\n          if phase == 'train':\n            loss.backward()\n            optimizer.step()\n\n        # default loss item is mean, therefore we multiply it with the number of items in the batch\n        running_loss += loss.item() * inputs.size(0)\n        running_corrects += torch.sum(preds == labels)\n\n      if phase == 'train':\n        scheduler.step()\n\n      epoch_loss = running_loss / dataset_sizes[phase]\n      epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n      print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n\n      # deep copy the model\n      if phase == 'val' and epoch_acc > best_acc:\n        best_acc = epoch_acc\n        best_model_wts = deepcopy(model.state_dict())\n\n      print()\n\n  time_elapsed = time.time() - since\n  print(\n      f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n  print(f'Best val Acc: {best_acc:4f}')\n\n  model.load_state_dict(best_model_wts)\n  return model\n","metadata":{"execution":{"iopub.execute_input":"2022-10-19T18:08:20.002296Z","iopub.status.busy":"2022-10-19T18:08:20.001842Z","iopub.status.idle":"2022-10-19T18:08:20.014065Z","shell.execute_reply":"2022-10-19T18:08:20.013052Z"},"papermill":{"duration":0.02213,"end_time":"2022-10-19T18:08:20.016495","exception":false,"start_time":"2022-10-19T18:08:19.994365","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualising Model Predictions","metadata":{"papermill":{"duration":0.006036,"end_time":"2022-10-19T18:08:20.028937","exception":false,"start_time":"2022-10-19T18:08:20.022901","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from matplotlib.image import AxesImage\n\n\ndef process_tensor_to_display(inp: Tensor) -> np.ndarray:\n  inp = inp.cpu().numpy().transpose((1, 2, 0))\n  mean = np.array([0.485, 0.456, 0.406])\n  std = np.array([0.229, 0.224, 0.225])\n\n  inp = std * inp + mean\n  np.clip(inp, 0, 1)\n\n  return inp\n","metadata":{"execution":{"iopub.execute_input":"2022-10-19T18:08:20.043629Z","iopub.status.busy":"2022-10-19T18:08:20.042884Z","iopub.status.idle":"2022-10-19T18:08:20.04868Z","shell.execute_reply":"2022-10-19T18:08:20.04777Z"},"papermill":{"duration":0.015604,"end_time":"2022-10-19T18:08:20.050835","exception":false,"start_time":"2022-10-19T18:08:20.035231","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualise_predictions(model: Module, num_images: int, n_rows: int, n_cols: int):\n  was_training = model.training\n  model.eval()\n  images_so_far = 0\n  fig, ax = plt.subplots(n_rows, n_cols)\n\n  with torch.no_grad():\n    for i, (inputs, labels) in enumerate(dataloaders['val']):\n      inputs, labels = inputs.to(device), labels.to(device)\n\n      outputs = model(inputs)\n      _, preds = torch.max(outputs, dim=1)\n\n      for j in range(inputs.size(0)):\n\n        # below call takes number of rows, number of cols, index of item that starts at 1\n        plotX, plotY = images_so_far // n_cols, images_so_far % n_cols\n        ax[plotX, plotY].imshow(process_tensor_to_display(inputs[j].detach()))\n        ax[plotX, plotY].axis('off')\n        ax[plotX, plotY].set_title(f\"{category_names[preds[j]]}\")\n        images_so_far += 1\n\n        # imshow(inputs[j].detach())\n\n        if images_so_far == num_images:\n          model.train(was_training)\n          return\n\n  model.train(was_training)\n","metadata":{"execution":{"iopub.execute_input":"2022-10-19T18:08:20.065086Z","iopub.status.busy":"2022-10-19T18:08:20.064302Z","iopub.status.idle":"2022-10-19T18:08:20.072515Z","shell.execute_reply":"2022-10-19T18:08:20.071706Z"},"papermill":{"duration":0.017246,"end_time":"2022-10-19T18:08:20.074457","exception":false,"start_time":"2022-10-19T18:08:20.057211","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Finetuning the convnet\n\nLoad a pretrained model and reset final fully connected layer","metadata":{"papermill":{"duration":0.006139,"end_time":"2022-10-19T18:08:20.086725","exception":false,"start_time":"2022-10-19T18:08:20.080586","status":"completed"},"tags":[]}},{"cell_type":"code","source":"model_ft = models.resnet18(pretrained=True)\nnum_ftrs = model_ft.fc.in_features\n\nmodel_ft.fc = nn.Linear(num_ftrs, len(category_names))\n\nmodel_ft = model_ft.to(device)","metadata":{"execution":{"iopub.execute_input":"2022-10-19T18:08:20.100956Z","iopub.status.busy":"2022-10-19T18:08:20.100386Z","iopub.status.idle":"2022-10-19T18:08:25.883782Z","shell.execute_reply":"2022-10-19T18:08:25.88283Z"},"papermill":{"duration":5.793172,"end_time":"2022-10-19T18:08:25.886212","exception":false,"start_time":"2022-10-19T18:08:20.09304","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\n\n# Observe that all parameters are being optimized\noptimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n\n# Decay LR by a factor of 0.1 every 7 epochs\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, 7, gamma=0.1)","metadata":{"execution":{"iopub.execute_input":"2022-10-19T18:08:25.901095Z","iopub.status.busy":"2022-10-19T18:08:25.900766Z","iopub.status.idle":"2022-10-19T18:08:25.907676Z","shell.execute_reply":"2022-10-19T18:08:25.906786Z"},"papermill":{"duration":0.01643,"end_time":"2022-10-19T18:08:25.909774","exception":false,"start_time":"2022-10-19T18:08:25.893344","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=30)","metadata":{"execution":{"iopub.execute_input":"2022-10-19T18:08:25.9236Z","iopub.status.busy":"2022-10-19T18:08:25.923339Z","iopub.status.idle":"2022-10-19T18:10:28.182895Z","shell.execute_reply":"2022-10-19T18:10:28.181222Z"},"papermill":{"duration":122.269028,"end_time":"2022-10-19T18:10:28.185199","exception":false,"start_time":"2022-10-19T18:08:25.916171","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualise_predictions(model_ft, 6, 2, 3)","metadata":{"execution":{"iopub.execute_input":"2022-10-19T18:10:28.207011Z","iopub.status.busy":"2022-10-19T18:10:28.206601Z","iopub.status.idle":"2022-10-19T18:10:28.837984Z","shell.execute_reply":"2022-10-19T18:10:28.836762Z"},"papermill":{"duration":0.644938,"end_time":"2022-10-19T18:10:28.840347","exception":false,"start_time":"2022-10-19T18:10:28.195409","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ConvNet as a Fixed Feature Extractor\n\n- Here we will freeze all the layers of the network, except for the final layer.\n- We need to set `requires_grad = False` for all those layers, so that their loss is not computed during the backward pass.\n","metadata":{"papermill":{"duration":0.011259,"end_time":"2022-10-19T18:10:28.864219","exception":false,"start_time":"2022-10-19T18:10:28.85296","status":"completed"},"tags":[]}},{"cell_type":"code","source":"model_conv = models.resnet34(pretrained=True)\n\nfor param in model_conv.parameters():\n  param.requires_grad = False","metadata":{"execution":{"iopub.execute_input":"2022-10-19T18:10:28.889394Z","iopub.status.busy":"2022-10-19T18:10:28.889029Z","iopub.status.idle":"2022-10-19T18:10:32.971733Z","shell.execute_reply":"2022-10-19T18:10:32.97062Z"},"papermill":{"duration":4.098731,"end_time":"2022-10-19T18:10:32.974654","exception":false,"start_time":"2022-10-19T18:10:28.875923","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_ftrs = model_conv.fc.in_features\nmodel_conv.fc = nn.Linear(num_ftrs, len(category_names))\n\nmodel_conv.to(device)","metadata":{"execution":{"iopub.execute_input":"2022-10-19T18:10:33.003351Z","iopub.status.busy":"2022-10-19T18:10:33.002652Z","iopub.status.idle":"2022-10-19T18:10:33.043484Z","shell.execute_reply":"2022-10-19T18:10:33.042545Z"},"papermill":{"duration":0.057451,"end_time":"2022-10-19T18:10:33.045449","exception":false,"start_time":"2022-10-19T18:10:32.987998","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\n\noptimizer = optim.SGD(model_conv.parameters(), 0.001, 0.9)\n\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer, 7, 0.01)","metadata":{"execution":{"iopub.execute_input":"2022-10-19T18:10:33.071132Z","iopub.status.busy":"2022-10-19T18:10:33.070572Z","iopub.status.idle":"2022-10-19T18:10:33.076807Z","shell.execute_reply":"2022-10-19T18:10:33.07572Z"},"papermill":{"duration":0.021306,"end_time":"2022-10-19T18:10:33.078882","exception":false,"start_time":"2022-10-19T18:10:33.057576","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train and Evaluate","metadata":{"papermill":{"duration":0.012041,"end_time":"2022-10-19T18:10:33.102502","exception":false,"start_time":"2022-10-19T18:10:33.090461","status":"completed"},"tags":[]}},{"cell_type":"code","source":"model_conv = train_model(model_conv, criterion, optimizer, exp_lr_scheduler)","metadata":{"execution":{"iopub.execute_input":"2022-10-19T18:10:33.12806Z","iopub.status.busy":"2022-10-19T18:10:33.127259Z","iopub.status.idle":"2022-10-19T18:12:10.068035Z","shell.execute_reply":"2022-10-19T18:12:10.066037Z"},"papermill":{"duration":96.955885,"end_time":"2022-10-19T18:12:10.070359","exception":false,"start_time":"2022-10-19T18:10:33.114474","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualise_predictions(model_conv, 10, 2, 5)","metadata":{"execution":{"iopub.execute_input":"2022-10-19T18:12:10.10258Z","iopub.status.busy":"2022-10-19T18:12:10.101562Z","iopub.status.idle":"2022-10-19T18:12:11.517083Z","shell.execute_reply":"2022-10-19T18:12:11.516091Z"},"papermill":{"duration":1.435856,"end_time":"2022-10-19T18:12:11.521222","exception":false,"start_time":"2022-10-19T18:12:10.085366","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.025669,"end_time":"2022-10-19T18:12:11.573778","exception":false,"start_time":"2022-10-19T18:12:11.548109","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}